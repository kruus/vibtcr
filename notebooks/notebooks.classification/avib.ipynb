{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "808e2dcc",
   "metadata": {},
   "source": [
    "# Attentive Variational Information Bottleneck\n",
    "\n",
    "In this notebook, we train and test the Attentive Variational Information Bottleneck (MVIB [1] with Attention of Experts) and MVIB on all datasets.\n",
    "\n",
    "[1] Microbiome-based disease prediction with multimodal variational information bottlenecks, Grazioli et al., https://www.biorxiv.org/node/2109522.external-links.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdd9626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T14:02:15.564982Z",
     "iopub.status.busy": "2023-10-12T14:02:15.564558Z",
     "iopub.status.idle": "2023-10-12T14:02:16.479671Z",
     "shell.execute_reply": "2023-10-12T14:02:16.479096Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from vibtcr.dataset import TCRDataset\n",
    "from vibtcr.mvib.mvib import MVIB\n",
    "from vibtcr.mvib.mvib_trainer import TrainerMVIB\n",
    "\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa957077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T14:02:16.485017Z",
     "iopub.status.busy": "2023-10-12T14:02:16.484692Z",
     "iopub.status.idle": "2023-10-12T14:02:16.490009Z",
     "shell.execute_reply": "2023-10-12T14:02:16.489469Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "metrics = [\n",
    "    'auROC',\n",
    "    'Accuracy',\n",
    "    'Recall',\n",
    "    'Precision',\n",
    "    'F1 score',\n",
    "    'auPRC'\n",
    "]\n",
    "\n",
    "def pr_auc(y_true, y_prob):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return pr_auc\n",
    "\n",
    "def get_scores(y_true, y_prob, y_pred):\n",
    "    \"\"\"\n",
    "    Compute a df with all classification metrics and respective scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = [\n",
    "        roc_auc_score(y_true, y_prob),\n",
    "        accuracy_score(y_true, y_pred),\n",
    "        recall_score(y_true, y_pred),\n",
    "        precision_score(y_true, y_pred),\n",
    "        f1_score(y_true, y_pred),\n",
    "        pr_auc(y_true, y_prob)\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(data={'score': scores, 'metrics': metrics})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314146e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T14:02:16.495139Z",
     "iopub.status.busy": "2023-10-12T14:02:16.494921Z",
     "iopub.status.idle": "2023-10-12T14:02:16.516668Z",
     "shell.execute_reply": "2023-10-12T14:02:16.516184Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_random_seed(random_seed):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "133637c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T14:02:16.520965Z",
     "iopub.status.busy": "2023-10-12T14:02:16.520816Z",
     "iopub.status.idle": "2023-10-12T14:02:16.524709Z",
     "shell.execute_reply": "2023-10-12T14:02:16.524220Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "login = os.getlogin( )\n",
    "DATA_BASE = f\"/home/{login}/Git/tcr/data/\"\n",
    "RESULTS_BASE = f\"/home/{login}/Git/tcr/notebooks/notebooks.classification/results/\"\n",
    "# To run in github checkout of vibtcr, after `unzip data.zip` ...\n",
    "RESULTS_BASE = os.path.join('.', 'results')\n",
    "DATA_BASE = os.path.join('..', '..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a04b4a78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T14:02:16.529064Z",
     "iopub.status.busy": "2023-10-12T14:02:16.528849Z",
     "iopub.status.idle": "2023-10-12T14:02:16.532166Z",
     "shell.execute_reply": "2023-10-12T14:02:16.531687Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "batch_size = 4096\n",
    "epochs = 500 #500 <-------------------------------------\n",
    "lr = 1e-3\n",
    "\n",
    "z_dim = 150\n",
    "early_stopper_patience = 50\n",
    "monitor = 'auROC'\n",
    "lr_scheduler_param = 10\n",
    "\n",
    "beta = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2174113-3ad9-45fb-9173-1245c127060d",
   "metadata": {},
   "source": [
    "# AVIB multimodal pooling of experts (aoe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae95e2d-4abd-4ec0-b210-178f48e1b405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T14:02:16.537319Z",
     "iopub.status.busy": "2023-10-12T14:02:16.537102Z",
     "iopub.status.idle": "2023-10-12T14:02:16.539893Z",
     "shell.execute_reply": "2023-10-12T14:02:16.539414Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# NOTE: This notebook runs several choices for \"joint_posterior\"\n",
    "#       Class BaseVIB supports:\n",
    "#         'peo' ~ \"product of experts\" ~ \"MVIB\" (multimodal) original paper\n",
    "#         'aoe' ~ \"attention of experts\" ~ \"AVIB\" (attentive)\n",
    "#         'max_pool'\n",
    "#         'avg_pool'\n",
    "joint_posterior = \"aoe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794a7f3",
   "metadata": {},
   "source": [
    "# alpha+beta set - peptide+CDR3b (AVIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f5b486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T14:02:16.545759Z",
     "iopub.status.busy": "2023-10-12T14:02:16.545610Z",
     "iopub.status.idle": "2023-10-12T14:38:34.310076Z",
     "shell.execute_reply": "2023-10-12T14:38:34.309615Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 86 | Best val score -0.915149 | DKL-prior 0.000509 | BCE 0.706523 | auROC 0.9151:  27%|██▋       | 135/500 [06:15<16:55,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 164 | Best val score -0.916218 | DKL-prior 0.000554 | BCE 0.879744 | auROC 0.9162:  43%|████▎     | 213/500 [10:11<13:43,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 74 | Best val score -0.918045 | DKL-prior 0.000480 | BCE 0.558302 | auROC 0.9180:  25%|██▍       | 123/500 [05:55<18:08,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 101 | Best val score -0.916223 | DKL-prior 0.000413 | BCE 0.649124 | auROC 0.9162:  30%|███       | 150/500 [07:13<16:51,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 78 | Best val score -0.920351 | DKL-prior 0.000545 | BCE 0.558462 | auROC 0.9204:  25%|██▌       | 127/500 [06:07<17:58,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 78\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None).scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)\n",
    "    run_name = f\"mvib.bimodal.{joint_posterior}.alpha+beta-only.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6c4fc",
   "metadata": {},
   "source": [
    "# alpha+beta set - peptide+CDR3b+CDR3a (AVIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9eeb2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T14:38:34.313473Z",
     "iopub.status.busy": "2023-10-12T14:38:34.313272Z",
     "iopub.status.idle": "2023-10-12T16:09:53.717839Z",
     "shell.execute_reply": "2023-10-12T16:09:53.717310Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 72 | Best val score -0.933601 | DKL-prior 0.000456 | BCE 0.537745 | auROC 0.9336:  24%|██▍       | 121/500 [18:58<59:24,  9.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 52 | Best val score -0.938146 | DKL-prior 0.000533 | BCE 0.524283 | auROC 0.9381:  20%|██        | 101/500 [15:57<1:03:03,  9.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 66 | Best val score -0.942532 | DKL-prior 0.000533 | BCE 0.480641 | auROC 0.9425:  23%|██▎       | 115/500 [18:09<1:00:47,  9.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 86 | Best val score -0.940843 | DKL-prior 0.000475 | BCE 0.584330 | auROC 0.9408:  27%|██▋       | 135/500 [20:46<56:10,  9.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 60 | Best val score -0.941849 | DKL-prior 0.000463 | BCE 0.440435 | auROC 0.9418:  22%|██▏       | 109/500 [16:43<59:58,  9.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 60\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col='tcra').scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col='tcra', scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col='tcra', scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col='tcra', scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"trimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    run_name = f\"mvib.trimodal.{joint_posterior}.alpha+beta-only.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "\n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=ds_test.cdr3a)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd7a799",
   "metadata": {},
   "source": [
    "# alpha+beta set - peptide+CDR3a (AVIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b299ba7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T16:09:53.720777Z",
     "iopub.status.busy": "2023-10-12T16:09:53.720562Z",
     "iopub.status.idle": "2023-10-12T16:40:43.386313Z",
     "shell.execute_reply": "2023-10-12T16:40:43.385769Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 78 | Best val score -0.923301 | DKL-prior 0.000444 | BCE 0.567158 | auROC 0.9233:  25%|██▌       | 127/500 [05:55<17:22,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 118 | Best val score -0.921938 | DKL-prior 0.000565 | BCE 0.776266 | auROC 0.9219:  33%|███▎      | 167/500 [07:55<15:48,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 66 | Best val score -0.930392 | DKL-prior 0.000586 | BCE 0.452523 | auROC 0.9304:  23%|██▎       | 115/500 [05:20<17:53,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 69 | Best val score -0.925276 | DKL-prior 0.000501 | BCE 0.480685 | auROC 0.9253:  24%|██▎       | 118/500 [05:28<17:41,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 74 | Best val score -0.928442 | DKL-prior 0.000483 | BCE 0.543335 | auROC 0.9284:  25%|██▍       | 123/500 [05:43<17:32,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 74\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcra').scaler\n",
    "    # we pass column `tcra` to `cdr3b_col` because TCRDataset expects to have the CDR3b attribute\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcra', scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcra', scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcra', scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    run_name = f\"mvib.bimodal-alpha.{joint_posterior}.alpha+beta-only.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "\n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f91524",
   "metadata": {},
   "source": [
    "# beta set (AVIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b1b0962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T16:40:43.389711Z",
     "iopub.status.busy": "2023-10-12T16:40:43.389328Z",
     "iopub.status.idle": "2023-10-12T18:17:22.450324Z",
     "shell.execute_reply": "2023-10-12T18:17:22.449849Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 207 | Best val score -0.831984 | DKL-prior 0.000568 | BCE 0.817977 | auROC 0.8320:  51%|█████     | 256/500 [17:58<17:07,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 311 | Best val score -0.841795 | DKL-prior 0.000570 | BCE 0.937354 | auROC 0.8418:  72%|███████▏  | 360/500 [24:48<09:39,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 228 | Best val score -0.840914 | DKL-prior 0.000551 | BCE 0.898606 | auROC 0.8409:  55%|█████▌    | 277/500 [19:35<15:46,  4.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 247 | Best val score -0.843472 | DKL-prior 0.000572 | BCE 0.880978 | auROC 0.8435:  59%|█████▉    | 296/500 [20:57<14:26,  4.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 127 | Best val score -0.836380 | DKL-prior 0.000609 | BCE 0.759371 | auROC 0.8364:  35%|███▌      | 176/500 [12:29<22:59,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 127\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'beta.csv'))\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None).scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    run_name = f\"mvib.bimodal.{joint_posterior}.beta-only.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b51a2d4",
   "metadata": {},
   "source": [
    "# full set: alpha+beta set + beta set (AVIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c62d12c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T18:17:22.453020Z",
     "iopub.status.busy": "2023-10-12T18:17:22.452859Z",
     "iopub.status.idle": "2023-10-12T20:18:36.707059Z",
     "shell.execute_reply": "2023-10-12T20:18:36.706597Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 165 | Best val score -0.818070 | DKL-prior 0.000638 | BCE 0.719234 | auROC 0.8181:  43%|████▎     | 214/500 [26:09<34:57,  7.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 166 | Best val score -0.810671 | DKL-prior 0.000614 | BCE 0.737749 | auROC 0.8107:  43%|████▎     | 215/500 [26:27<35:04,  7.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 127 | Best val score -0.813910 | DKL-prior 0.000587 | BCE 0.697707 | auROC 0.8139:  35%|███▌      | 176/500 [21:43<40:00,  7.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 130 | Best val score -0.816822 | DKL-prior 0.000588 | BCE 0.724327 | auROC 0.8168:  36%|███▌      | 179/500 [22:11<39:47,  7.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 137 | Best val score -0.813370 | DKL-prior 0.000594 | BCE 0.761324 | auROC 0.8134:  37%|███▋      | 186/500 [23:01<38:51,  7.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 137\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'beta.csv'))\n",
    "df2 = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "df = pd.concat([df1, df2]).reset_index()\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None).scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    run_name = f\"mvib.bimodal.{joint_posterior}.full.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./',\n",
    "                            filename=os.path.join(RESULTS_BASE,f\"{run_name}.pth\"))\n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd8ddc4-830d-4c1e-a703-ef8887a512d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# MVIB multimodal pooling of experts (poe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dba8cc00-9619-4143-8912-c5c1d1279918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T20:18:36.709806Z",
     "iopub.status.busy": "2023-10-12T20:18:36.709486Z",
     "iopub.status.idle": "2023-10-12T20:18:36.711859Z",
     "shell.execute_reply": "2023-10-12T20:18:36.711495Z"
    }
   },
   "outputs": [],
   "source": [
    "joint_posterior = \"poe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b951b-c003-4486-97ef-d6895dc6d0e6",
   "metadata": {},
   "source": [
    "# alpha+beta set - peptide+CDR3b (MVIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34925e2c-5802-4ef3-85ae-2d8b33f352ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T20:18:36.713981Z",
     "iopub.status.busy": "2023-10-12T20:18:36.713810Z",
     "iopub.status.idle": "2023-10-12T20:48:41.896429Z",
     "shell.execute_reply": "2023-10-12T20:48:41.895946Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 87 | Best val score -0.911952 | DKL-prior 0.000372 | BCE 0.673360 | auROC 0.9120:  27%|██▋       | 136/500 [05:36<14:59,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 126 | Best val score -0.914753 | DKL-prior 0.000360 | BCE 0.742800 | auROC 0.9148:  35%|███▌      | 175/500 [07:09<13:17,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 89 | Best val score -0.915633 | DKL-prior 0.000407 | BCE 0.624047 | auROC 0.9156:  28%|██▊       | 138/500 [05:36<14:41,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 87 | Best val score -0.913535 | DKL-prior 0.000386 | BCE 0.684263 | auROC 0.9135:  27%|██▋       | 136/500 [05:31<14:47,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 91 | Best val score -0.916320 | DKL-prior 0.000371 | BCE 0.635772 | auROC 0.9163:  28%|██▊       | 140/500 [05:41<14:38,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 91\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None).scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)\n",
    "    run_name = f\"mvib.bimodal.{joint_posterior}.alpha+beta-only.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770deae1-f4d0-46cd-b6da-19770ced4d3a",
   "metadata": {},
   "source": [
    "# alpha+beta set - peptide+CDR3b+CDR3a (MVIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "362ad44e-3189-494f-89a0-36ccebd8ca1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T20:48:41.899129Z",
     "iopub.status.busy": "2023-10-12T20:48:41.898927Z",
     "iopub.status.idle": "2023-10-12T22:31:19.595644Z",
     "shell.execute_reply": "2023-10-12T22:31:19.595189Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 80 | Best val score -0.933487 | DKL-prior 0.000351 | BCE 0.582936 | auROC 0.9335:  26%|██▌       | 129/500 [17:17<49:43,  8.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 82 | Best val score -0.934239 | DKL-prior 0.000373 | BCE 0.595437 | auROC 0.9342:  26%|██▌       | 131/500 [17:38<49:41,  8.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 67 | Best val score -0.937545 | DKL-prior 0.000356 | BCE 0.468431 | auROC 0.9375:  23%|██▎       | 116/500 [15:32<51:27,  8.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 151 | Best val score -0.936985 | DKL-prior 0.000350 | BCE 0.791356 | auROC 0.9370:  40%|████      | 200/500 [26:37<39:56,  7.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 137 | Best val score -0.940832 | DKL-prior 0.000356 | BCE 0.668724 | auROC 0.9408:  37%|███▋      | 186/500 [24:45<41:47,  7.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 137\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col='tcra').scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col='tcra', scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col='tcra', scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col='tcra', scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"trimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    run_name = f\"mvib.trimodal.{joint_posterior}.alpha+beta-only.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "\n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=ds_test.cdr3a)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313c9031-5090-490a-9f28-5b1ee3205db7",
   "metadata": {},
   "source": [
    "# alpha+beta set - peptide+CDR3a (MVIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77f26a63-a5bf-47e5-a47f-39515aec22ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T22:31:19.598352Z",
     "iopub.status.busy": "2023-10-12T22:31:19.598192Z",
     "iopub.status.idle": "2023-10-12T23:02:23.607377Z",
     "shell.execute_reply": "2023-10-12T23:02:23.606851Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 73 | Best val score -0.920042 | DKL-prior 0.000416 | BCE 0.514892 | auROC 0.9200:  24%|██▍       | 122/500 [04:56<15:18,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 119 | Best val score -0.918556 | DKL-prior 0.000368 | BCE 0.769417 | auROC 0.9186:  34%|███▎      | 168/500 [06:48<13:28,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 92 | Best val score -0.925117 | DKL-prior 0.000399 | BCE 0.553487 | auROC 0.9251:  28%|██▊       | 141/500 [05:42<14:32,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 87 | Best val score -0.921203 | DKL-prior 0.000391 | BCE 0.568877 | auROC 0.9212:  27%|██▋       | 136/500 [05:31<14:47,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 137 | Best val score -0.927519 | DKL-prior 0.000346 | BCE 0.647315 | auROC 0.9275:  37%|███▋      | 186/500 [07:34<12:47,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 137\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcra').scaler\n",
    "    # we pass column `tcra` to `cdr3b_col` because TCRDataset expects to have the CDR3b attribute\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcra', scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcra', scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcra', scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    run_name = f\"mvib.bimodal-alpha.{joint_posterior}.alpha+beta-only.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "\n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca54760f-4922-44a6-ad07-9b407128fa7f",
   "metadata": {},
   "source": [
    "# beta set (MVIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9347894c-ab49-445b-8b6f-e6ac58b341b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-12T23:02:23.610298Z",
     "iopub.status.busy": "2023-10-12T23:02:23.610085Z",
     "iopub.status.idle": "2023-10-13T00:36:21.465376Z",
     "shell.execute_reply": "2023-10-13T00:36:21.464921Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 379 | Best val score -0.834778 | DKL-prior 0.000371 | BCE 0.771687 | auROC 0.8348:  86%|████████▌ | 428/500 [26:20<04:25,  3.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 161 | Best val score -0.829311 | DKL-prior 0.000377 | BCE 0.691996 | auROC 0.8293:  42%|████▏     | 210/500 [12:41<17:31,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 262 | Best val score -0.839996 | DKL-prior 0.000351 | BCE 0.705013 | auROC 0.8400:  62%|██████▏   | 311/500 [18:59<11:32,  3.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 258 | Best val score -0.841148 | DKL-prior 0.000368 | BCE 0.709435 | auROC 0.8411:  61%|██████▏   | 307/500 [18:30<11:38,  3.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 225 | Best val score -0.835524 | DKL-prior 0.000362 | BCE 0.713573 | auROC 0.8355:  55%|█████▍    | 274/500 [16:38<13:43,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 225\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'beta.csv'))\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None).scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    run_name = f\"mvib.bimodal.{joint_posterior}.beta-only.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641adbb-f2d6-4c98-9d30-f6f7a56bd779",
   "metadata": {},
   "source": [
    "# full set: alpha+beta set + beta set (MVIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6a50434-8505-4285-b8ac-8e86bb0897b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T00:36:21.468258Z",
     "iopub.status.busy": "2023-10-13T00:36:21.468056Z",
     "iopub.status.idle": "2023-10-13T03:56:13.998618Z",
     "shell.execute_reply": "2023-10-13T03:56:13.998047Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 397 | Best val score -0.819986 | DKL-prior 0.000434 | BCE 0.692449 | auROC 0.8200:  89%|████████▉ | 446/500 [47:10<05:42,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 334 | Best val score -0.815213 | DKL-prior 0.000407 | BCE 0.695995 | auROC 0.8152:  77%|███████▋  | 383/500 [40:44<12:26,  6.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 283 | Best val score -0.816175 | DKL-prior 0.000392 | BCE 0.664660 | auROC 0.8162:  66%|██████▋   | 332/500 [35:09<17:47,  6.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 278 | Best val score -0.819015 | DKL-prior 0.000387 | BCE 0.646202 | auROC 0.8190:  65%|██████▌   | 327/500 [34:52<18:27,  6.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 332 | Best val score -0.822531 | DKL-prior 0.000422 | BCE 0.689946 | auROC 0.8225:  76%|███████▌  | 381/500 [40:22<12:36,  6.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 332\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'beta.csv'))\n",
    "df2 = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "df = pd.concat([df1, df2]).reset_index()\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None).scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    run_name = f\"mvib.bimodal.{joint_posterior}.full.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b505744-194b-49b3-a473-e4025b0f82cf",
   "metadata": {},
   "source": [
    "# Max pooling of experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d60f0422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T03:56:14.001448Z",
     "iopub.status.busy": "2023-10-13T03:56:14.001287Z",
     "iopub.status.idle": "2023-10-13T03:56:14.005041Z",
     "shell.execute_reply": "2023-10-13T03:56:14.004320Z"
    }
   },
   "outputs": [],
   "source": [
    "joint_posterior = \"max_pool\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0ad1a",
   "metadata": {},
   "source": [
    "# alpha+beta set - peptide+CDR3b (max pooling of experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b168b6ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T03:56:14.007356Z",
     "iopub.status.busy": "2023-10-13T03:56:14.007114Z",
     "iopub.status.idle": "2023-10-13T04:39:37.542030Z",
     "shell.execute_reply": "2023-10-13T04:39:37.541575Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 172 | Best val score -0.909271 | DKL-prior 0.000485 | BCE 0.579490 | auROC 0.9093:  44%|████▍     | 221/500 [09:28<11:58,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 165 | Best val score -0.913073 | DKL-prior 0.000586 | BCE 0.518310 | auROC 0.9131:  43%|████▎     | 214/500 [09:11<12:17,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 151 | Best val score -0.912707 | DKL-prior 0.000554 | BCE 0.525336 | auROC 0.9127:  40%|████      | 200/500 [08:32<12:49,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 125 | Best val score -0.907327 | DKL-prior 0.000439 | BCE 0.481588 | auROC 0.9073:  35%|███▍      | 174/500 [07:26<13:55,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 141 | Best val score -0.913202 | DKL-prior 0.000461 | BCE 0.457095 | auROC 0.9132:  38%|███▊      | 190/500 [08:11<13:21,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 141\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None).scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    run_name = f\"mvib.bimodal.{joint_posterior}.alpha+beta-only.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78df89b7",
   "metadata": {},
   "source": [
    "# alpha+beta set - peptide+CDR3b+CDR3a  (max pooling of experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b759731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T04:39:37.544804Z",
     "iopub.status.busy": "2023-10-13T04:39:37.544599Z",
     "iopub.status.idle": "2023-10-13T06:22:57.552590Z",
     "shell.execute_reply": "2023-10-13T06:22:57.552061Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 80 | Best val score -0.928553 | DKL-prior 0.000517 | BCE 0.405969 | auROC 0.9286:  26%|██▌       | 129/500 [18:07<52:06,  8.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 82 | Best val score -0.927299 | DKL-prior 0.000539 | BCE 0.450303 | auROC 0.9273:  26%|██▌       | 131/500 [18:29<52:04,  8.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 94 | Best val score -0.930142 | DKL-prior 0.000568 | BCE 0.435805 | auROC 0.9301:  29%|██▊       | 143/500 [20:10<50:23,  8.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 91 | Best val score -0.931659 | DKL-prior 0.000504 | BCE 0.441023 | auROC 0.9317:  28%|██▊       | 140/500 [19:51<51:02,  8.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 135 | Best val score -0.937005 | DKL-prior 0.000676 | BCE 0.394142 | auROC 0.9370:  37%|███▋      | 184/500 [25:55<44:30,  8.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 135\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col='tcra').scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col='tcra', scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col='tcra', scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col='tcra', scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"trimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    run_name = f\"mvib.trimodal.{joint_posterior}.alpha+beta-only.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=ds_test.cdr3a)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce83121",
   "metadata": {},
   "source": [
    "# Average pooling of experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c79e67b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T06:22:57.557685Z",
     "iopub.status.busy": "2023-10-13T06:22:57.557518Z",
     "iopub.status.idle": "2023-10-13T06:22:57.560264Z",
     "shell.execute_reply": "2023-10-13T06:22:57.559825Z"
    }
   },
   "outputs": [],
   "source": [
    "joint_posterior = \"avg_pool\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c16c885",
   "metadata": {},
   "source": [
    "# alpha+beta set - peptide+CDR3b (average pooling of experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3315a8a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T06:22:57.565973Z",
     "iopub.status.busy": "2023-10-13T06:22:57.565819Z",
     "iopub.status.idle": "2023-10-13T06:58:36.191240Z",
     "shell.execute_reply": "2023-10-13T06:58:36.190764Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 80 | Best val score -0.904815 | DKL-prior 0.000479 | BCE 0.551604 | auROC 0.9048:  26%|██▌       | 129/500 [05:08<14:46,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 204 | Best val score -0.910141 | DKL-prior 0.000432 | BCE 0.775137 | auROC 0.9101:  51%|█████     | 253/500 [10:11<09:56,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 88 | Best val score -0.910858 | DKL-prior 0.000470 | BCE 0.525894 | auROC 0.9109:  27%|██▋       | 137/500 [05:30<14:35,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 120 | Best val score -0.905538 | DKL-prior 0.000456 | BCE 0.652001 | auROC 0.9055:  34%|███▍      | 169/500 [06:46<13:15,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 138 | Best val score -0.909851 | DKL-prior 0.000444 | BCE 0.669654 | auROC 0.9099:  37%|███▋      | 187/500 [07:32<12:37,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 138\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None).scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    run_name = f\"mvib.bimodal.{joint_posterior}.alpha+beta-only.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250724ec",
   "metadata": {},
   "source": [
    "# alpha+beta set - peptide+CDR3b+CDR3a  (average pooling of experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca5c6558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-13T06:58:36.193931Z",
     "iopub.status.busy": "2023-10-13T06:58:36.193730Z",
     "iopub.status.idle": "2023-10-13T09:16:45.134400Z",
     "shell.execute_reply": "2023-10-13T09:16:45.133814Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 172 | Best val score -0.930989 | DKL-prior 0.000552 | BCE 0.751971 | auROC 0.9310:  44%|████▍     | 221/500 [29:08<36:46,  7.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 201 | Best val score -0.928251 | DKL-prior 0.000550 | BCE 0.858718 | auROC 0.9283:  50%|█████     | 250/500 [33:05<33:05,  7.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 167 | Best val score -0.934883 | DKL-prior 0.000559 | BCE 0.645326 | auROC 0.9349:  43%|████▎     | 216/500 [28:23<37:19,  7.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 120 | Best val score -0.927328 | DKL-prior 0.000566 | BCE 0.639885 | auROC 0.9273:  34%|███▍      | 169/500 [22:11<43:28,  7.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 137 | Best val score -0.935942 | DKL-prior 0.000577 | BCE 0.619351 | auROC 0.9359:  37%|███▋      | 186/500 [24:34<41:29,  7.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 137\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col='tcra').scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col='tcra', scaler=scaler)\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.sign, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col='tcra', scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col='tcra', scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"trimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    run_name = f\"mvib.trimodal.{joint_posterior}.alpha+beta-only.rep-{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=ds_test.cdr3a)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(os.path.join(RESULTS_BASE, f\"{run_name}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f33353b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vibtcr] *",
   "language": "python",
   "name": "conda-env-vibtcr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
