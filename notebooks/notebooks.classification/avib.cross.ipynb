{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7129de6",
   "metadata": {},
   "source": [
    "# Attentive Variational Information Bottleneck\n",
    "\n",
    "In this notebook, we train the Attentive Variational Information Bottleneck on the `α+β set` and test on the `β set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa957077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T13:19:07.046522Z",
     "iopub.status.busy": "2023-10-19T13:19:07.046244Z",
     "iopub.status.idle": "2023-10-19T13:19:07.897385Z",
     "shell.execute_reply": "2023-10-19T13:19:07.896812Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "metrics = [\n",
    "    'auROC',\n",
    "    'Accuracy',\n",
    "    'Recall',\n",
    "    'Precision',\n",
    "    'F1 score',\n",
    "    'auPRC'\n",
    "]\n",
    "\n",
    "def pr_auc(y_true, y_prob):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return pr_auc\n",
    "\n",
    "def get_scores(y_true, y_prob, y_pred):\n",
    "    \"\"\"\n",
    "    Compute a df with all classification metrics and respective scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = [\n",
    "        roc_auc_score(y_true, y_prob),\n",
    "        accuracy_score(y_true, y_pred),\n",
    "        recall_score(y_true, y_pred),\n",
    "        precision_score(y_true, y_pred),\n",
    "        f1_score(y_true, y_pred),\n",
    "        pr_auc(y_true, y_prob)\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(data={'score': scores, 'metrics': metrics})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133637c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T13:19:07.902257Z",
     "iopub.status.busy": "2023-10-19T13:19:07.902055Z",
     "iopub.status.idle": "2023-10-19T13:19:07.906297Z",
     "shell.execute_reply": "2023-10-19T13:19:07.905584Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "login = os.getlogin( )\n",
    "DATA_BASE = f\"/home/{login}/Git/tcr/data/\"\n",
    "RESULTS_BASE = f\"/home/{login}/Git/tcr/notebooks/notebooks.classification/results/\"\n",
    "# To run in github checkout of vibtcr, after `unzip data.zip` ...\n",
    "RESULTS_BASE = os.path.join('.', 'results')\n",
    "#FIGURES_BASE = os.path.join('.', 'figures')\n",
    "DATA_BASE = os.path.join('..', '..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04b4a78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T13:19:07.911765Z",
     "iopub.status.busy": "2023-10-19T13:19:07.911546Z",
     "iopub.status.idle": "2023-10-19T13:19:07.915302Z",
     "shell.execute_reply": "2023-10-19T13:19:07.914582Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "batch_size = 4096\n",
    "epochs = 500 #200\n",
    "lr = 1e-3\n",
    "z_dim = 150\n",
    "beta = 1e-6\n",
    "early_stopper_patience = 20\n",
    "monitor = 'auROC'\n",
    "lr_scheduler_param = 10\n",
    "joint_posterior = \"aoe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f5b486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-19T13:19:07.920793Z",
     "iopub.status.busy": "2023-10-19T13:19:07.920644Z",
     "iopub.status.idle": "2023-10-19T13:54:11.181515Z",
     "shell.execute_reply": "2023-10-19T13:54:11.180972Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 92 | Best val score -0.920935 | DKL-prior 0.000642 | BCE 0.617460 | auROC 0.9209:  22%|██▏       | 111/500 [06:25<22:31,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 126 | Best val score -0.918078 | DKL-prior 0.000558 | BCE 0.704900 | auROC 0.9181:  29%|██▉       | 145/500 [08:17<20:16,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 78 | Best val score -0.918534 | DKL-prior 0.000550 | BCE 0.544574 | auROC 0.9185:  19%|█▉        | 97/500 [05:33<23:07,  3.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 76 | Best val score -0.920117 | DKL-prior 0.000542 | BCE 0.517762 | auROC 0.9201:  19%|█▉        | 95/500 [05:27<23:15,  3.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 114 | Best val score -0.922357 | DKL-prior 0.000484 | BCE 0.643442 | auROC 0.9224:  27%|██▋       | 133/500 [07:35<20:58,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 114\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from vibtcr.dataset import TCRDataset\n",
    "from vibtcr.mvib.mvib import MVIB\n",
    "from vibtcr.mvib.mvib_trainer import TrainerMVIB\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "scaler = TCRDataset(df.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None).scaler\n",
    "\n",
    "df_test = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'beta.csv'))\n",
    "ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "\n",
    "for i in range(5):  # 5 independent train/val splits\n",
    "    df_train, df_val = train_test_split(df, test_size=0.2, stratify=df.sign, random_state=i)\n",
    "    \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)\n",
    "    run_name = f\"mvib.ab2b\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "# save results for further analysis\n",
    "df_test.to_csv(os.path.join(RESULTS_BASE, \"{run_name}.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
