{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7129de6",
   "metadata": {},
   "source": [
    "# Attentive Variational Information Bottleneck\n",
    "\n",
    "In this notebook, we train the Attentive Variational Information Bottleneck on the `α+β set` and test on the `β set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa957077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "metrics = [\n",
    "    'auROC',\n",
    "    'Accuracy',\n",
    "    'Recall',\n",
    "    'Precision',\n",
    "    'F1 score',\n",
    "    'auPRC'\n",
    "]\n",
    "\n",
    "def pr_auc(y_true, y_prob):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return pr_auc\n",
    "\n",
    "def get_scores(y_true, y_prob, y_pred):\n",
    "    \"\"\"\n",
    "    Compute a df with all classification metrics and respective scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = [\n",
    "        roc_auc_score(y_true, y_prob),\n",
    "        accuracy_score(y_true, y_pred),\n",
    "        recall_score(y_true, y_pred),\n",
    "        precision_score(y_true, y_pred),\n",
    "        f1_score(y_true, y_pred),\n",
    "        pr_auc(y_true, y_prob)\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(data={'score': scores, 'metrics': metrics})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133637c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "login = os.getlogin( )\n",
    "DATA_BASE = f\"/home/{login}/Git/tcr/data/\"\n",
    "RESULTS_BASE = f\"/home/{login}/Git/tcr/notebooks/notebooks.classification/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04b4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "batch_size = 4096\n",
    "epochs = 200\n",
    "lr = 1e-3\n",
    "z_dim = 150\n",
    "beta = 1e-6\n",
    "early_stopper_patience = 20\n",
    "monitor = 'auROC'\n",
    "lr_scheduler_param = 10\n",
    "joint_posterior = \"aoe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f5b486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 72 | Score -0.920575 | DKL-prior 0.000536 | BCE 0.482500 | auROC 0.9206:  46%|████▌     | 91/200 [03:14<03:53,  2.14s/it]\n",
      "[VAL] Best epoch 54 | Score -0.915860 | DKL-prior 0.000438 | BCE 0.435013 | auROC 0.9159:  36%|███▋      | 73/200 [02:35<04:30,  2.13s/it]\n",
      "[VAL] Best epoch 66 | Score -0.915766 | DKL-prior 0.000543 | BCE 0.442076 | auROC 0.9158:  42%|████▎     | 85/200 [03:01<04:05,  2.13s/it]\n",
      "[VAL] Best epoch 95 | Score -0.920989 | DKL-prior 0.000535 | BCE 0.522592 | auROC 0.9210:  57%|█████▋    | 114/200 [04:02<03:02,  2.13s/it]\n",
      "[VAL] Best epoch 75 | Score -0.919583 | DKL-prior 0.000529 | BCE 0.465375 | auROC 0.9196:  47%|████▋     | 94/200 [03:21<03:46,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from vibtcr.dataset import TCRDataset\n",
    "from vibtcr.mvib.mvib import MVIB\n",
    "from vibtcr.mvib.mvib_trainer import TrainerMVIB\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "df = pd.read_csv(DATA_BASE + 'alpha-beta-splits/alpha-beta.csv')\n",
    "scaler = TCRDataset(df.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None).scaler\n",
    "\n",
    "df_test = pd.read_csv(DATA_BASE + 'alpha-beta-splits/beta.csv')\n",
    "ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "\n",
    "for i in range(5):  # 5 independent train/val splits\n",
    "    df_train, df_val = train_test_split(df, test_size=0.2, stratify=df.sign, random_state=i)\n",
    "    \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "# save results for further analysis\n",
    "df_test.to_csv(\n",
    "    RESULTS_BASE + \"mvib.ab2b.csv\",\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
