{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7129de6",
   "metadata": {},
   "source": [
    "# Attentive Variational Information Bottleneck\n",
    "\n",
    "In this notebook, we train the Attentive Variational Information Bottleneck on the `α+β set` and test on the `β set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa957077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T16:27:31.920840Z",
     "iopub.status.busy": "2023-10-20T16:27:31.920506Z",
     "iopub.status.idle": "2023-10-20T16:27:33.267816Z",
     "shell.execute_reply": "2023-10-20T16:27:33.266779Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "metrics = [\n",
    "    'auROC',\n",
    "    'Accuracy',\n",
    "    'Recall',\n",
    "    'Precision',\n",
    "    'F1 score',\n",
    "    'auPRC'\n",
    "]\n",
    "\n",
    "def pr_auc(y_true, y_prob):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return pr_auc\n",
    "\n",
    "def get_scores(y_true, y_prob, y_pred):\n",
    "    \"\"\"\n",
    "    Compute a df with all classification metrics and respective scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = [\n",
    "        roc_auc_score(y_true, y_prob),\n",
    "        accuracy_score(y_true, y_pred),\n",
    "        recall_score(y_true, y_pred),\n",
    "        precision_score(y_true, y_pred),\n",
    "        f1_score(y_true, y_pred),\n",
    "        pr_auc(y_true, y_prob)\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(data={'score': scores, 'metrics': metrics})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133637c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T16:27:33.272189Z",
     "iopub.status.busy": "2023-10-20T16:27:33.271317Z",
     "iopub.status.idle": "2023-10-20T16:27:33.278170Z",
     "shell.execute_reply": "2023-10-20T16:27:33.277105Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "login = os.getlogin( )\n",
    "DATA_BASE = f\"/home/{login}/Git/tcr/data/\"\n",
    "RESULTS_BASE = f\"/home/{login}/Git/tcr/notebooks/notebooks.classification/results/\"\n",
    "# To run in github checkout of vibtcr, after `unzip data.zip` ...\n",
    "RESULTS_BASE = os.path.join('.', 'results')\n",
    "#FIGURES_BASE = os.path.join('.', 'figures')\n",
    "DATA_BASE = os.path.join('..', '..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04b4a78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T16:27:33.281301Z",
     "iopub.status.busy": "2023-10-20T16:27:33.280751Z",
     "iopub.status.idle": "2023-10-20T16:27:33.286252Z",
     "shell.execute_reply": "2023-10-20T16:27:33.284972Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1')\n",
    "batch_size = 4096\n",
    "epochs = 500 #200\n",
    "lr = 1e-3\n",
    "z_dim = 150\n",
    "beta = 1e-6\n",
    "early_stopper_patience = 20\n",
    "monitor = 'auROC'\n",
    "lr_scheduler_param = 10\n",
    "joint_posterior = \"aoe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f5b486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-20T16:27:33.289873Z",
     "iopub.status.busy": "2023-10-20T16:27:33.289572Z",
     "iopub.status.idle": "2023-10-20T16:55:32.438061Z",
     "shell.execute_reply": "2023-10-20T16:55:32.437488Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 34 | Best val score -0.916439 | DKL-prior 0.000446 | BCE 0.427117 | auROC 0.9164:  11%|█         | 53/500 [03:11<26:57,  3.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 84 | Best val score -0.919749 | DKL-prior 0.000527 | BCE 0.532550 | auROC 0.9197:  21%|██        | 103/500 [06:14<24:01,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 49 | Best val score -0.913686 | DKL-prior 0.000562 | BCE 0.461638 | auROC 0.9137:  14%|█▎        | 68/500 [04:08<26:18,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 72 | Best val score -0.919430 | DKL-prior 0.000483 | BCE 0.463048 | auROC 0.9194:  18%|█▊        | 91/500 [05:33<24:57,  3.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 88 | Best val score -0.920861 | DKL-prior 0.000550 | BCE 0.506731 | auROC 0.9209:  21%|██▏       | 107/500 [06:30<23:54,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving best model: epoch 88\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from vibtcr.dataset import TCRDataset\n",
    "from vibtcr.mvib.mvib import MVIB\n",
    "from vibtcr.mvib.mvib_trainer import TrainerMVIB\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'alpha-beta.csv'))\n",
    "scaler = TCRDataset(df.copy(), torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None).scaler\n",
    "\n",
    "df_test = pd.read_csv(os.path.join(DATA_BASE, 'alpha-beta-splits', 'beta.csv'))\n",
    "ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "\n",
    "for i in range(5):  # 5 independent train/val splits\n",
    "    df_train, df_val = train_test_split(df, test_size=0.2, stratify=df.sign, random_state=i)\n",
    "    \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_train[df_train.sign == 0].shape[0], df_train[df_train.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_train.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='tcrb', cdr3a_col=None, scaler=scaler)\n",
    "    class_count = np.array([df_val[df_val.sign == 0].shape[0], df_val[df_val.sign == 1].shape[0]])\n",
    "    weight = 1. / class_count\n",
    "    samples_weight = torch.tensor([weight[s] for s in df_val.sign])\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)\n",
    "    run_name = f\"mvib.ab2b-rep{i}\"\n",
    "    trainer.save_checkpoint(checkpoint, folder='./', filename=os.path.join(RESULTS_BASE, f\"{run_name}.pth\"))\n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "# save results for further analysis\n",
    "df_test.to_csv(os.path.join(RESULTS_BASE, \"mvib.ab2b.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
