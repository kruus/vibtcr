{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b3d83d8",
   "metadata": {},
   "source": [
    "# Baselines for TCR\n",
    "The notebook `dataset-creation.ipyn` creates two dataset: the `α+β set`, and the `β set`. The `α+β set` contains `(CDR3α, CDR3β, peptide)` samples. The `β set` contains `(CDR3β, peptide)` samples.\n",
    "\n",
    "In this notebook, we do experiments on ERGO II and NetTCR2.0 using them as baseline for our research. We train and test on the `β set`.\n",
    "\n",
    "For testing, we operate 5 independent train/test splits of `β set` with different random seeds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c5ce2",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5b1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import random\n",
    "import math\n",
    "from scipy import interp\n",
    "import statistics \n",
    "\n",
    "from tcrmodels.ergo2.model import ERGO2\n",
    "from tcrmodels.nettcr2.model import NetTCR2\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import collections\n",
    "from matplotlib import colors\n",
    "from numpy.random import normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9ed6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'AUROC',\n",
    "    'Accuracy',\n",
    "    #'Recall',\n",
    "    'Precision',\n",
    "    'F1 score',\n",
    "    'AUPR'\n",
    "]\n",
    "\n",
    "def pr_auc(y_true, y_prob):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return pr_auc\n",
    "\n",
    "def get_scores(y_true, y_prob, y_pred):\n",
    "    \"\"\"\n",
    "    Compute a df with all classification metrics and respective scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = [\n",
    "        roc_auc_score(y_true, y_prob),\n",
    "        accuracy_score(y_true, y_pred),\n",
    "        #recall_score(y_true, y_pred),\n",
    "        precision_score(y_true, y_pred),\n",
    "        f1_score(y_true, y_pred),\n",
    "        pr_auc(y_true, y_prob)\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(data={'score': scores, 'metrics': metrics})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2610b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "blosum50_20aa = {\n",
    "    'A': np.array((5,-2,-1,-2,-1,-1,-1,0,-2,-1,-2,-1,-1,-3,-1,1,0,-3,-2,0)),\n",
    "    'R': np.array((-2,7,-1,-2,-4,1,0,-3,0,-4,-3,3,-2,-3,-3,-1,-1,-3,-1,-3)),\n",
    "    'N': np.array((-1,-1,7,2,-2,0,0,0,1,-3,-4,0,-2,-4,-2,1,0,-4,-2,-3)),\n",
    "    'D': np.array((-2,-2,2,8,-4,0,2,-1,-1,-4,-4,-1,-4,-5,-1,0,-1,-5,-3,-4)),\n",
    "    'C': np.array((-1,-4,-2,-4,13,-3,-3,-3,-3,-2,-2,-3,-2,-2,-4,-1,-1,-5,-3,-1)),\n",
    "    'Q': np.array((-1,1,0,0,-3,7,2,-2,1,-3,-2,2,0,-4,-1,0,-1,-1,-1,-3)),\n",
    "    'E': np.array((-1,0,0,2,-3,2,6,-3,0,-4,-3,1,-2,-3,-1,-1,-1,-3,-2,-3)),\n",
    "    'G': np.array((0,-3,0,-1,-3,-2,-3,8,-2,-4,-4,-2,-3,-4,-2,0,-2,-3,-3,-4)),\n",
    "    'H': np.array((-2,0,1,-1,-3,1,0,-2,10,-4,-3,0,-1,-1,-2,-1,-2,-3,2,-4)),\n",
    "    'I': np.array((-1,-4,-3,-4,-2,-3,-4,-4,-4,5,2,-3,2,0,-3,-3,-1,-3,-1,4)),\n",
    "    'L': np.array((-2,-3,-4,-4,-2,-2,-3,-4,-3,2,5,-3,3,1,-4,-3,-1,-2,-1,1)),\n",
    "    'K': np.array((-1,3,0,-1,-3,2,1,-2,0,-3,-3,6,-2,-4,-1,0,-1,-3,-2,-3)),\n",
    "    'M': np.array((-1,-2,-2,-4,-2,0,-2,-3,-1,2,3,-2,7,0,-3,-2,-1,-1,0,1)),\n",
    "    'F': np.array((-3,-3,-4,-5,-2,-4,-3,-4,-1,0,1,-4,0,8,-4,-3,-2,1,4,-1)),\n",
    "    'P': np.array((-1,-3,-2,-1,-4,-1,-1,-2,-2,-3,-4,-1,-3,-4,10,-1,-1,-4,-3,-3)),\n",
    "    'S': np.array((1,-1,1,0,-1,0,-1,0,-1,-3,-3,0,-2,-3,-1,5,2,-4,-2,-2)),\n",
    "    'T': np.array((0,-1,0,-1,-1,-1,-1,-2,-2,-1,-1,-1,-1,-2,-1,2,5,-3,-2,0)),\n",
    "    'W': np.array((-3,-3,-4,-5,-5,-1,-3,-3,-3,-3,-2,-3,-1,1,-4,-4,-3,15,2,-3)),\n",
    "    'Y': np.array((-2,-1,-2,-3,-3,-1,-2,-3,2,-1,-1,-2,0,4,-3,-2,-2,2,8,-1)),\n",
    "    'V': np.array((0,-3,-3,-4,-1,-3,-3,-4,-4,4,1,-3,1,-1,-3,-2,0,-3,-1,5))\n",
    "}\n",
    "\n",
    "def enc_list_bl_max_len(aas, blosum, max_seq_len):\n",
    "    '''\n",
    "    blosum encoding of a list of amino acid sequences with padding \n",
    "    to a max length\n",
    "\n",
    "    parameters:\n",
    "        - aa_seqs : list with AA sequences\n",
    "        - blosum : dictionary: key= AA, value= blosum encoding\n",
    "        - max_seq_len: common length for padding\n",
    "    returns:\n",
    "        padded_aa_encoding : array of padded amino acids encoding\n",
    "    '''\n",
    "    encoding_len = len(blosum['A'])\n",
    "    padded_aa_encoding = np.zeros((encoding_len * max_seq_len))\n",
    "    \n",
    "    # encode amino acids\n",
    "    for i, aa in enumerate(aas):\n",
    "        padded_aa_encoding[i*encoding_len:(i+1)*encoding_len] = blosum[aa]\n",
    "        \n",
    "    return padded_aa_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1005830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abbasi et al. implementation of LUPI-SVM does not predict probabilities\n",
    "# we should do Platt scaling to estimate probabilities of a SVM\n",
    "# but since that would be a complex implementation, we use a sigmoid\n",
    "from scipy.stats import logistic\n",
    "\n",
    "def sigmoid(x):\n",
    "    return logistic.cdf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2639bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "login = os.getlogin( )\n",
    "DATA_BASE = f\"/home/{login}/Git/tcr/data/\"\n",
    "RESULTS_BASE = f\"/home/{login}/Git/tcr/notebooks/notebooks.classification/results/\"\n",
    "FIGURES_BASE = f\"/home/{login}/Git/tcr/notebooks/notebooks.classification/figures/\"\n",
    "# To run in github checkout of vibtcr, after `unzip data.zip` ...\n",
    "DATA_BASE = os.path.join('..', '..', 'data')\n",
    "RESULTS_BASE = os.path.join('.', 'results')\n",
    "FIGURES_BASE = os.path.join('.', 'figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545d281",
   "metadata": {},
   "source": [
    "# NetTCR2.0 - Peptide+CDR3β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96770fdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2602927923.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_118295/2602927923.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    test_files = ('(β-set', [])\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "df_dataset = pd.read_csv(os.path.join(DATA_BASE, \"alpha-beta-splits\", \"beta.csv\"))\n",
    "test_files = ('(β-set', [])\n",
    "results_nettcr2 = []\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    df_train, df_test = train_test_split(df_dataset, test_size=0.2, random_state=i)\n",
    "    test_files[1].append(df_test.reset_index())\n",
    "\n",
    "    model = NetTCR2(\n",
    "        architecture=\"b\", \n",
    "        single_chain_column='tcrb',\n",
    "        peptide_column='peptide',\n",
    "        label_column='sign',\n",
    "        max_pep_len=df_dataset.peptide.str.len().max(), \n",
    "        max_cdr3_len=df_dataset.tcrb.str.len().max()\n",
    "    )\n",
    "    model.train(df_train, epochs=1000);\n",
    "\n",
    "    prediction_df = model.test(test_files[1][i])\n",
    "    scores_df = get_scores(\n",
    "        y_true=prediction_df['sign'].to_numpy(), \n",
    "        y_prob=prediction_df['prediction'].to_numpy(),\n",
    "        y_pred=prediction_df['prediction'].to_numpy().round(),\n",
    "    )\n",
    "    scores_df['experiment'] = \"train_β-set_test_\"+test_files[0]\n",
    "    results_nettcr2.append(scores_df)\n",
    "    test_files[1][i]['prediction_'+str(i)] = prediction_df['prediction']\n",
    "        \n",
    "results_nettcr2_df = pd.concat(results_nettcr2)\n",
    "\n",
    "# save results for further analysis\n",
    "for i, test_file in enumerate(test_files[1]):\n",
    "    test_file.to_csv(os.path.join(RESULTS_BASE, f\"nettcr2.baseline.beta-only.rep-{i}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fdbe84",
   "metadata": {},
   "source": [
    "# ERGO II - Peptide+CDR3β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "878188f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3377764427.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_118295/3377764427.py\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    results_ergo2 = []\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "# the ERGO II data presents some files with a given header, and some others with a different one\n",
    "map_keys = {\n",
    "    'tcra': 'TRA',\n",
    "    'tcrb': 'TRB',\n",
    "    'va': 'TRAV',\n",
    "    'ja': 'TRAJ',\n",
    "    'vb': 'TRBV',\n",
    "    'jb': 'TRBJ',\n",
    "    't_cell_type': 'T-Cell-Type',\n",
    "    'peptide': 'Peptide',\n",
    "    'mhc': 'MHC',\n",
    "    'protein': 'protein',\n",
    "    'sign': 'sign'\n",
    "}\n",
    "\n",
    "df_dataset = pd.read_csv(os.path.join(DATA_BASE, \"alpha-beta-splits\", \"beta.csv\"))\n",
    "results_ergo2 = []\n",
    "test_files = ('(β-set', [])\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    df_train, df_test = train_test_split(df_dataset, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # the ERGO II implementation expected the following columns to be preset in the dataframe\n",
    "    # even if they are not used\n",
    "    df_test['va'] = pd.NA\n",
    "    df_train['va'] = pd.NA\n",
    "    df_test['vb'] = pd.NA\n",
    "    df_train['vb'] = pd.NA\n",
    "    df_test['ja'] = pd.NA\n",
    "    df_train['ja'] = pd.NA\n",
    "    df_test['jb'] = pd.NA\n",
    "    df_train['jb'] = pd.NA\n",
    "    df_test['mhc'] = pd.NA\n",
    "    df_train['mhc'] = pd.NA\n",
    "    df_test['t_cell_type'] = pd.NA\n",
    "    df_train['t_cell_type'] = pd.NA\n",
    "    df_test['protein'] = pd.NA\n",
    "    df_train['protein'] = pd.NA\n",
    "\n",
    "    # using \"UNK\" for identifier of missing CDR3α for test set\n",
    "    df_test['tcra'] = \"UNK\"\n",
    "    df_train['tcra'] = \"UNK\"\n",
    "\n",
    "    df_test = df_test.rename(columns={c: map_keys[c] for c in df_test.columns})\n",
    "    \n",
    "    test_files[1].append(df_test.reset_index())\n",
    "\n",
    "    model = ERGO2(\n",
    "        gpu=[0],\n",
    "        use_alpha=False,\n",
    "        random_seed=i,\n",
    "        train_val_ratio=.2,\n",
    "    )\n",
    "    model.train(df_train);\n",
    "\n",
    "    prediction_df = model.test(test_files[1][i])\n",
    "    scores_df = get_scores(\n",
    "        y_true=prediction_df['sign'].to_numpy(), \n",
    "        y_prob=prediction_df['prediction'].to_numpy(),\n",
    "        y_pred=prediction_df['prediction'].to_numpy().round(),\n",
    "    )\n",
    "    scores_df['experiment'] = \"train_β-set_test_\"+test_files[0]\n",
    "    results_ergo2.append(scores_df)\n",
    "    test_files[1][i]['prediction_'+str(i)] = prediction_df['prediction']\n",
    "        \n",
    "results_ergo2_df = pd.concat(results_ergo2)\n",
    "\n",
    "# save results for further analysis\n",
    "for i, test_file in enumerate(test_files[1]):\n",
    "    test_file.to_csv(\n",
    "        os.path.join(RESULTS_BASE, f\"ergo2.baseline.beta-only.rep-{i}.csv\"),\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91948307",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "239752c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/nettcr2.baseline.beta-only.rep-0.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_118295/3707613009.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m predictions_files = [\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#('RF-HPO | peptide+β',   [pd.read_csv(os.path.join(RESULTS_BASE, f\"rf-hpo.baseline.alpha+beta-only.rep-{i}.csv\")) for i in range(5)]),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'NetTCR2.0 | peptide+β'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULTS_BASE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"nettcr2.baseline.beta-only.rep-{i}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'ERGO II | peptide+β'\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULTS_BASE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"ergo2.baseline.beta-only.rep-{i}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'AVIB | peptide+β'\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULTS_BASE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"mvib.bimodal.aoe.beta-only.rep-{i}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_118295/3707613009.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m predictions_files = [\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#('RF-HPO | peptide+β',   [pd.read_csv(os.path.join(RESULTS_BASE, f\"rf-hpo.baseline.alpha+beta-only.rep-{i}.csv\")) for i in range(5)]),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'NetTCR2.0 | peptide+β'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULTS_BASE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"nettcr2.baseline.beta-only.rep-{i}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'ERGO II | peptide+β'\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULTS_BASE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"ergo2.baseline.beta-only.rep-{i}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'AVIB | peptide+β'\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESULTS_BASE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"mvib.bimodal.aoe.beta-only.rep-{i}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tcrmodels/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tcrmodels/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tcrmodels/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tcrmodels/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tcrmodels/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tcrmodels/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tcrmodels/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tcrmodels/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/nettcr2.baseline.beta-only.rep-0.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "login = os.getlogin( )\n",
    "DATA_BASE = f\"/home/{login}/Git/tcr/data/\"\n",
    "RESULTS_BASE = f\"/home/{login}/Git/tcr/notebooks/notebooks.classification/results/\"\n",
    "FIGURES_BASE = f\"/home/{login}/Git/tcr/notebooks/notebooks.classification/figures/\"\n",
    "# To run in github checkout of vibtcr, after `unzip data.zip` ...\n",
    "DATA_BASE = os.path.join('..', '..', 'data')\n",
    "RESULTS_BASE = os.path.join('.', 'results')\n",
    "FIGURES_BASE = os.path.join('.', 'figures')\n",
    "predictions_files = [\n",
    "    #('RF-HPO | peptide+β',   [pd.read_csv(os.path.join(RESULTS_BASE, f\"rf-hpo.baseline.alpha+beta-only.rep-{i}.csv\")) for i in range(5)]),\n",
    "    ('NetTCR2.0 | peptide+β', [pd.read_csv(os.path.join(RESULTS_BASE, f\"nettcr2.baseline.beta-only.rep-{i}.csv\")) for i in range(5)]),\n",
    "    ('ERGO II | peptide+β',   [pd.read_csv(os.path.join(RESULTS_BASE, f\"ergo2.baseline.beta-only.rep-{i}.csv\")) for i in range(5)]),\n",
    "    ('AVIB | peptide+β',      [pd.read_csv(os.path.join(RESULTS_BASE, f\"mvib.bimodal.aoe.beta-only.rep-{i}.csv\")) for i in range(5)]),\n",
    "    #('PVIB | α-privileged',  [pd.read_csv(os.path.join(RESULTS_BASE, f\"pvib.results.aoe.alpha+beta-only.rep-{i}.csv\")) for i in range(5)]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf36844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('axes', axisbelow=True)\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    for predictions_file in predictions_files:\n",
    "        prediction_df = predictions_file[1][i]\n",
    "        if f'prediction_{i}' in prediction_df.columns:\n",
    "            if \"LUPI-SVM\" in predictions_file[0]:\n",
    "                scores_df = get_scores(\n",
    "                    y_true=prediction_df['sign'].to_numpy(), \n",
    "                    y_prob=sigmoid(prediction_df[f'prediction_{i}'].to_numpy()),\n",
    "                    y_pred=np.sign(prediction_df[f'prediction_{i}'].to_numpy().round()).clip(min=0),\n",
    "                )\n",
    "            else:\n",
    "                scores_df = get_scores(\n",
    "                    y_true=prediction_df['sign'].to_numpy(), \n",
    "                    y_prob=prediction_df[f'prediction_{i}'].to_numpy(),\n",
    "                    y_pred=prediction_df[f'prediction_{i}'].to_numpy().round(),\n",
    "                )\n",
    "            scores_df['Model'] = predictions_file[0]\n",
    "            results.append(scores_df)\n",
    "        \n",
    "results_df = pd.concat(results).rename(columns={'metrics': 'Metrics', 'score': 'Score'})\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "ax = sns.barplot(\n",
    "    x=\"Metrics\",\n",
    "    y=\"Score\", \n",
    "    hue=\"Model\", \n",
    "    data=results_df,\n",
    "    palette=sns.color_palette(\"magma\", len(predictions_files))\n",
    ")\n",
    "ax.set_title('TCR recognition | Train: β-set | Test: β-set')\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.legend(loc='best')\n",
    "legend = plt.legend(frameon = 1)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('white')\n",
    "ax.grid(axis='y')\n",
    "\n",
    "plt.savefig(os.path.join(FIGURES_BASE, \"baseline.beta-only.svg\"), format='svg', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(FIGURES_BASE, \"baseline.beta-only.png\"), format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.groupby(['Metrics', 'Model']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ste = results_df.groupby(['Metrics', 'Model']).std()\n",
    "ste['Score'] = ste['Score'].apply(lambda x: x / 5)\n",
    "ste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8da761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rc('axes', axisbelow=True)\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "sns.set_palette('magma', len(predictions_files))\n",
    "\n",
    "\n",
    "def make_roc_curve_plot(ax, true_values_list, predicted_values_list, cutoff, model_label):\n",
    "    \"\"\"Calculate ROC and AUC from lists of true and predicted values and draw.\"\"\"\n",
    "\n",
    "    tprs = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    auc = []\n",
    "    for true_values, predicted_values in zip(true_values_list, predicted_values_list):\n",
    "        fpr, tpr, thresholds = roc_curve(true_values, predicted_values)\n",
    "        auc.append(roc_auc_score(true_values, predicted_values))\n",
    "        tpr = interp(base_fpr, fpr, tpr)\n",
    "        tpr[0] = 0.0\n",
    "        tprs.append(tpr)\n",
    "    \n",
    "    tprs = np.array(tprs)\n",
    "    mean_tprs = tprs.mean(axis=0)\n",
    "\n",
    "    ax.plot(base_fpr, mean_tprs, label=model_label+str(f\" | AUROC: {statistics.mean(auc):.3f}\"))\n",
    "    \n",
    "    ax.set_title(\"ROC Curve | Train: β-set | Test: β-set\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.legend()\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    \n",
    "#     for fp, tp, threshold in zip(fpr, tpr, thresholds):\n",
    "#         if threshold < cutoff:\n",
    "#             ax.plot(fp, tp, marker='o', markersize=10, color='grey', alpha=0.75)\n",
    "#             break\n",
    "\n",
    "\n",
    "def make_uninformative_roc(ax):\n",
    "    ax.plot([0, 1], [0, 1], c='grey', linestyle='dashed', alpha=0.5, label=\"Uninformative test\")\n",
    "    ax.legend()\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend(facecolor=\"white\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for predictions_file in predictions_files:\n",
    "    true_values_list, predicted_values_list = [], []\n",
    "    for i in range(5):\n",
    "        prediction_df = predictions_file[1][i]\n",
    "        true_values_list.append(prediction_df['sign'].to_numpy())\n",
    "        if \"LUPI-SVM\" in predictions_file[0]:\n",
    "            predicted_values_list.append(sigmoid(prediction_df[f'prediction_{i}'].to_numpy()))\n",
    "        else:\n",
    "            predicted_values_list.append(prediction_df[f'prediction_{i}'].to_numpy())\n",
    "\n",
    "    make_roc_curve_plot(\n",
    "        ax, \n",
    "        true_values_list, \n",
    "        predicted_values_list, \n",
    "        0.9,\n",
    "        predictions_file[0]\n",
    "    )\n",
    "make_uninformative_roc(ax)\n",
    "ax.tick_params(axis='x', pad=15)\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.legend(loc='best')\n",
    "legend = plt.legend(frameon = 1)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('white')\n",
    "\n",
    "plt.savefig(os.path.join(FIGURES_BASE, \"roc.beta-only.svg\"), format='svg', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(FIGURES_BASE, \"roc.beta-only.png\"), format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c6d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rc('axes', axisbelow=True)\n",
    "\n",
    "def make_prc_curve_plot(ax, true_values, predicted_values, model_label):\n",
    "    \"\"\"Calculate PRC and AUC from lists of true and predicted values and draw.\"\"\"\n",
    "    \n",
    "    reversed_mean_precision = 0.0\n",
    "    base_recall = np.linspace(1, 0, 100)\n",
    "    auc = []\n",
    "    \n",
    "    for true_values, predicted_values in zip(true_values_list, predicted_values_list):\n",
    "        precision, recall, thresholds = precision_recall_curve(true_values, predicted_values)\n",
    "        auc.append(pr_auc(true_values, predicted_values))\n",
    "        reversed_recall = np.fliplr([recall])[0]\n",
    "        reversed_precision = np.fliplr([precision])[0]\n",
    "        reversed_mean_precision += interp(base_recall, reversed_recall, reversed_precision)\n",
    "    \n",
    "    reversed_mean_precision /= 5\n",
    "    \n",
    "    ax.plot(base_recall, reversed_mean_precision, label=model_label+str(f\" | AUPR: {statistics.mean(auc):.3f}\"))\n",
    "    \n",
    "    ax.set_title(\"Precision-Recall Curve | Train: β-set | Test: β-set\")\n",
    "    ax.set_ylabel(\"Precision\")\n",
    "    ax.set_xlabel(\"Recall\")\n",
    "    ax.legend()\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for predictions_file in predictions_files:\n",
    "    true_values_list, predicted_values_list = [], []\n",
    "    for i in range(5):\n",
    "        prediction_df = predictions_file[1][i]\n",
    "        true_values_list.append(prediction_df['sign'].to_numpy())\n",
    "        if \"LUPI-SVM\" in predictions_file[0]:  # LUPI-SSVM\n",
    "            predicted_values_list.append(sigmoid(prediction_df[f'prediction_{i}'].to_numpy()))\n",
    "        else:\n",
    "            predicted_values_list.append(prediction_df[f'prediction_{i}'].to_numpy())\n",
    "\n",
    "    make_prc_curve_plot(\n",
    "        ax, \n",
    "        true_values_list, \n",
    "        predicted_values_list, \n",
    "        predictions_file[0]\n",
    "    )\n",
    "\n",
    "ax.tick_params(axis='x', pad=15)\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax.legend(loc='best')\n",
    "legend = plt.legend(frameon = 1)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('white')\n",
    "plt.savefig(os.path.join(FIGURES_BASE, \"prc.beta-only.svg\"), format='svg', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(FIGURES_BASE, \"prc.beta-only.png\"), format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d5de8",
   "metadata": {},
   "source": [
    "# MVIB - Experts comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a62fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_files = [\n",
    "    ('AVIB (AoE) | peptide+β', [pd.read_csv(os.path.join(RESULTS_BASE, f\"mvib.bimodal.aoe.beta-only.rep-{i}.csv\")) for i in range(5)]),\n",
    "    ('MVIB (PoE) | peptide+β', [pd.read_csv(os.path.join(RESULTS_BASE, f\"mvib.bimodal.poe.beta-only.rep-{i}.csv\")) for i in range(5)]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e99ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('axes', axisbelow=True)\n",
    "\n",
    "\n",
    "results = []\n",
    "colors = [\"#55DCFF\", \"#F5F542\", ]\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    for predictions_file in predictions_files:\n",
    "        prediction_df = predictions_file[1][i]\n",
    "        if f'prediction_{i}' in prediction_df.columns:\n",
    "            scores_df = get_scores(\n",
    "                y_true=prediction_df['sign'].to_numpy(), \n",
    "                y_prob=prediction_df[f'prediction_{i}'].to_numpy(),\n",
    "                y_pred=prediction_df[f'prediction_{i}'].to_numpy().round(),\n",
    "            )\n",
    "            scores_df['Model'] = predictions_file[0]\n",
    "            results.append(scores_df)\n",
    "        \n",
    "results_df = pd.concat(results).rename(columns={'metrics': 'Metrics', 'score': 'Score'})\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "ax = sns.barplot(\n",
    "    x=\"Metrics\",\n",
    "    y=\"Score\", \n",
    "    hue=\"Model\", \n",
    "    data=results_df,\n",
    "    palette=sns.color_palette(colors, 4)\n",
    ")\n",
    "ax.set_title('Experts comparison | Train: β-set | Test: β-set')\n",
    "ax.legend(loc='best')\n",
    "ax.grid(axis='y')\n",
    "legend = plt.legend(frameon = 1)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('white')\n",
    "plt.savefig(os.path.join(FIGURES_BASE, \"experts-comparison.beta-only.svg\"), format='svg', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(FIGURES_BASE, \"experts-comparison.beta-only.png\"), format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.groupby(['Metrics', 'Model']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0635a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.groupby(['Metrics', 'Model']).std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tcrmodels]",
   "language": "python",
   "name": "conda-env-tcrmodels-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
