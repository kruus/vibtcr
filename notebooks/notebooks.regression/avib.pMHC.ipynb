{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "808e2dcc",
   "metadata": {},
   "source": [
    "# peptide-MHC binding affinity regression\n",
    "\n",
    "In this notebook, we train and test the Attentive Variational Information Bottleneck on peptide+MHC class II data to predict binding affinity. We also do experiments with the baseline and ablation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fdd9626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from vibtcr.dataset import TCRDataset\n",
    "from vibtcr.mvib.mvib import MVIB\n",
    "from vibtcr.mvib.mvib_trainer import TrainerMVIB\n",
    "\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa957077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "metrics = ['MSE', 'RMSE', 'R2']\n",
    "\n",
    "def get_scores(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute a df with all regression metrics and respective scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = [\n",
    "        mean_squared_error(y_true, y_pred),\n",
    "        mean_absolute_error(y_true, y_pred),\n",
    "        r2_score(y_true, y_pred),\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(data={'score': scores, 'metrics': metrics})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "314146e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(random_seed):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133637c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "login = os.getlogin( )\n",
    "DATA_ROOT = f\"/home/{login}/Git/tcr/data/mhc/NetMHCIIpan_train/\"\n",
    "RESULTS_BASE = f\"/home/{login}/Git/tcr/notebooks/notebooks.regression/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a04b4a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:4')\n",
    "\n",
    "batch_size = 4096\n",
    "epochs = 1000\n",
    "lr = 1e-3\n",
    "\n",
    "z_dim = 150\n",
    "early_stopper_patience = 30\n",
    "monitor = 'loss'\n",
    "lr_scheduler_param = 10\n",
    "loss = \"mse\"\n",
    "\n",
    "beta = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9794a7f3",
   "metadata": {},
   "source": [
    "# PoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5c3c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_posterior = \"poe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77f5b486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 296 | Best val score 0.026977 | DKL-prior 0.000165 | MSE 0.026813 |:  32%|███▎      | 325/1000 [08:48<18:18,  1.63s/it]\n",
      "[VAL] Best epoch 402 | Best val score 0.026374 | DKL-prior 0.000178 | MSE 0.026195 |:  43%|████▎     | 431/1000 [11:37<15:20,  1.62s/it]\n",
      "[VAL] Best epoch 320 | Best val score 0.026815 | DKL-prior 0.000166 | MSE 0.026649 |:  35%|███▍      | 349/1000 [09:25<17:34,  1.62s/it]\n",
      "[VAL] Best epoch 389 | Best val score 0.026709 | DKL-prior 0.000170 | MSE 0.026539 |:  42%|████▏     | 418/1000 [11:35<16:08,  1.66s/it]\n",
      "[VAL] Best epoch 302 | Best val score 0.027491 | DKL-prior 0.000165 | MSE 0.027326 |:  33%|███▎      | 331/1000 [09:33<19:19,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_BASE + 'netmhcIIpan4.csv')\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='mhc', cdr3a_col=None, gt_col='BA').scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='mhc', cdr3a_col=None, scaler=scaler, gt_col='BA')\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='mhc', cdr3a_col=None, scaler=scaler, gt_col='BA')\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='mhc', cdr3a_col=None, scaler=scaler, gt_col='BA')\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param,\n",
    "        loss=loss\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(\n",
    "        RESULTS_BASE + f\"mvib.{joint_posterior}.pMHC.rep-{i}.csv\",\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6c4fc",
   "metadata": {},
   "source": [
    "# AoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3822b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_posterior = \"aoe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc9eeb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 191 | Best val score 0.026043 | DKL-prior 0.000214 | MSE 0.025829 |:  22%|██▏       | 220/1000 [06:45<23:56,  1.84s/it]\n",
      "[VAL] Best epoch 282 | Best val score 0.025615 | DKL-prior 0.000205 | MSE 0.025409 |:  31%|███       | 311/1000 [09:20<20:41,  1.80s/it]\n",
      "[VAL] Best epoch 263 | Best val score 0.025968 | DKL-prior 0.000174 | MSE 0.025795 |:  29%|██▉       | 292/1000 [08:45<21:13,  1.80s/it]\n",
      "[VAL] Best epoch 233 | Best val score 0.026508 | DKL-prior 0.000201 | MSE 0.026308 |:  26%|██▌       | 262/1000 [07:52<22:11,  1.80s/it]\n",
      "[VAL] Best epoch 255 | Best val score 0.026357 | DKL-prior 0.000150 | MSE 0.026207 |:  28%|██▊       | 284/1000 [08:32<21:32,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_BASE + 'netmhcIIpan4.csv')\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='mhc', cdr3a_col=None, gt_col='BA').scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='mhc', cdr3a_col=None, scaler=scaler, gt_col='BA')\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='mhc', cdr3a_col=None, scaler=scaler, gt_col='BA')\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='mhc', cdr3a_col=None, scaler=scaler, gt_col='BA')\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param,\n",
    "        loss=loss\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(\n",
    "        RESULTS_BASE + f\"mvib.{joint_posterior}.pMHC.rep-{i}.csv\",\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f91524",
   "metadata": {},
   "source": [
    "# Average Pooling of Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c158f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_posterior = \"avg_pool\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b1b0962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 262 | Best val score 0.028497 | DKL-prior 0.000207 | MSE 0.028290 |:  29%|██▉       | 291/1000 [07:51<19:07,  1.62s/it]\n",
      "[VAL] Best epoch 332 | Best val score 0.028016 | DKL-prior 0.000209 | MSE 0.027807 |:  36%|███▌      | 361/1000 [09:46<17:19,  1.63s/it]\n",
      "[VAL] Best epoch 374 | Best val score 0.027719 | DKL-prior 0.000211 | MSE 0.027508 |:  40%|████      | 403/1000 [10:55<16:11,  1.63s/it]\n",
      "[VAL] Best epoch 327 | Best val score 0.028083 | DKL-prior 0.000205 | MSE 0.027878 |:  36%|███▌      | 356/1000 [09:34<17:19,  1.61s/it]\n",
      "[VAL] Best epoch 300 | Best val score 0.028713 | DKL-prior 0.000210 | MSE 0.028503 |:  33%|███▎      | 329/1000 [09:01<18:24,  1.65s/it]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_BASE + 'netmhcIIpan4.csv')\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='mhc', cdr3a_col=None, gt_col='BA').scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='mhc', cdr3a_col=None, scaler=scaler, gt_col='BA')\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='mhc', cdr3a_col=None, scaler=scaler, gt_col='BA')\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='mhc', cdr3a_col=None, scaler=scaler, gt_col='BA')\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param,\n",
    "        loss=loss\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(\n",
    "        RESULTS_BASE + f\"mvib.{joint_posterior}.pMHC.rep-{i}.csv\",\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b51a2d4",
   "metadata": {},
   "source": [
    "# Max Pooling of Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd266049",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_posterior = \"max_pool\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c62d12c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[VAL] Best epoch 149 | Best val score 0.033145 | DKL-prior 0.000225 | MSE 0.032920 |:  18%|█▊        | 178/1000 [04:58<22:56,  1.67s/it]\n",
      "[VAL] Best epoch 141 | Best val score 0.035133 | DKL-prior 0.000220 | MSE 0.034913 |:  17%|█▋        | 170/1000 [04:52<23:48,  1.72s/it]\n",
      "[VAL] Best epoch 109 | Best val score 0.034712 | DKL-prior 0.000215 | MSE 0.034498 |:  14%|█▍        | 138/1000 [03:53<24:19,  1.69s/it]\n",
      "[VAL] Best epoch 181 | Best val score 0.033408 | DKL-prior 0.000206 | MSE 0.033202 |:  21%|██        | 210/1000 [05:57<22:25,  1.70s/it]\n",
      "[VAL] Best epoch 113 | Best val score 0.035078 | DKL-prior 0.000206 | MSE 0.034872 |:  14%|█▍        | 142/1000 [04:05<24:41,  1.73s/it]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_BASE + 'netmhcIIpan4.csv')\n",
    "\n",
    "for i in range(5):  # 5 independent train/test splits\n",
    "    set_random_seed(i)\n",
    "\n",
    "    df_train, df_test = train_test_split(df.copy(), test_size=0.2, random_state=i)\n",
    "\n",
    "    scaler = TCRDataset(df_train.copy(), torch.device(\"cpu\"), cdr3b_col='mhc', cdr3a_col=None, gt_col='BA').scaler\n",
    "\n",
    "    ds_test = TCRDataset(df_test, torch.device(\"cpu\"), cdr3b_col='mhc', cdr3a_col=None, scaler=scaler, gt_col='BA')\n",
    "\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, random_state=i)\n",
    "        \n",
    "    # train loader with balanced sampling\n",
    "    ds_train = TCRDataset(df_train, device, cdr3b_col='mhc', cdr3a_col=None, scaler=scaler, gt_col='BA')\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    # val loader with balanced sampling\n",
    "    ds_val = TCRDataset(df_val, device, cdr3b_col='mhc', cdr3a_col=None, scaler=scaler, gt_col='BA')\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        ds_val,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    model = MVIB(z_dim=z_dim, device=device, joint_posterior=joint_posterior).to(device)\n",
    "\n",
    "    trainer = TrainerMVIB(\n",
    "        model,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        beta=beta,\n",
    "        checkpoint_dir=\".\",\n",
    "        mode=\"bimodal\",\n",
    "        lr_scheduler_param=lr_scheduler_param,\n",
    "        loss=loss\n",
    "    )\n",
    "    checkpoint = trainer.train(train_loader, val_loader, early_stopper_patience, monitor)    \n",
    "    \n",
    "    # test\n",
    "    model = MVIB.from_checkpoint(checkpoint, torch.device(\"cpu\"))\n",
    "    pred = model.classify(pep=ds_test.pep, cdr3b=ds_test.cdr3b, cdr3a=None)\n",
    "    pred = pred.detach().numpy()\n",
    "    df_test['prediction_'+str(i)] = pred.squeeze().tolist()\n",
    "\n",
    "    # save results for further analysis\n",
    "    df_test.to_csv(\n",
    "        RESULTS_BASE + f\"mvib.{joint_posterior}.pMHC.rep-{i}.csv\",\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3bd77d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_BASE = f\"/home/{login}/Git/tcr/notebooks/notebooks.regression/results/\"\n",
    "FIGURES_BASE = f\"/home/{login}/Git/tcr/notebooks/notebooks.regression/figures/\"\n",
    "\n",
    "predictions_files = [\n",
    "    ('MVIB', [pd.read_csv(RESULTS_BASE + f\"mvib.poe.pMHC.rep-{i}.csv\") for i in range(5)]),\n",
    "    ('AvgPOOLoE', [pd.read_csv(RESULTS_BASE + f\"mvib.avg_pool.pMHC.rep-{i}.csv\") for i in range(5)]),\n",
    "    ('MaxPOOLeE', [pd.read_csv(RESULTS_BASE + f\"mvib.max_pool.pMHC.rep-{i}.csv\") for i in range(5)]),\n",
    "    ('AVIB', [pd.read_csv(RESULTS_BASE + f\"mvib.aoe.pMHC.rep-{i}.csv\") for i in range(5)]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fe86408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 118.27it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    for predictions_file in predictions_files:\n",
    "        prediction_df = predictions_file[1][i]\n",
    "        if f'prediction_{i}' in prediction_df.columns:\n",
    "            scores_df = get_scores(\n",
    "                y_true=prediction_df['BA'].to_numpy(), \n",
    "                y_pred=prediction_df[f'prediction_{i}'].to_numpy(),\n",
    "            )\n",
    "            scores_df['Model'] = predictions_file[0]\n",
    "            results.append(scores_df)\n",
    "        \n",
    "results_df = pd.concat(results).rename(columns={'metrics': 'Metrics', 'score': 'Score'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcafca82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">MSE</th>\n",
       "      <th>AVIB</th>\n",
       "      <td>0.029876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgPOOLoE</th>\n",
       "      <td>0.032929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MVIB</th>\n",
       "      <td>0.031270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxPOOLeE</th>\n",
       "      <td>0.036157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">R2</th>\n",
       "      <th>AVIB</th>\n",
       "      <td>0.558945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgPOOLoE</th>\n",
       "      <td>0.513889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MVIB</th>\n",
       "      <td>0.538357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxPOOLeE</th>\n",
       "      <td>0.466210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">RMSE</th>\n",
       "      <th>AVIB</th>\n",
       "      <td>0.133265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgPOOLoE</th>\n",
       "      <td>0.140310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MVIB</th>\n",
       "      <td>0.137003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxPOOLeE</th>\n",
       "      <td>0.149769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Metrics Model              \n",
       "MSE     AVIB       0.029876\n",
       "        AvgPOOLoE  0.032929\n",
       "        MVIB       0.031270\n",
       "        MaxPOOLeE  0.036157\n",
       "R2      AVIB       0.558945\n",
       "        AvgPOOLoE  0.513889\n",
       "        MVIB       0.538357\n",
       "        MaxPOOLeE  0.466210\n",
       "RMSE    AVIB       0.133265\n",
       "        AvgPOOLoE  0.140310\n",
       "        MVIB       0.137003\n",
       "        MaxPOOLeE  0.149769"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.groupby(['Metrics', 'Model']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ffe2e9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">MSE</th>\n",
       "      <th>AVIB</th>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgPOOLoE</th>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MVIB</th>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxPOOLeE</th>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">R2</th>\n",
       "      <th>AVIB</th>\n",
       "      <td>0.001120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgPOOLoE</th>\n",
       "      <td>0.003546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MVIB</th>\n",
       "      <td>0.001231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxPOOLeE</th>\n",
       "      <td>0.001570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">RMSE</th>\n",
       "      <th>AVIB</th>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgPOOLoE</th>\n",
       "      <td>0.000449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MVIB</th>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxPOOLeE</th>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Score\n",
       "Metrics Model              \n",
       "MSE     AVIB       0.000071\n",
       "        AvgPOOLoE  0.000245\n",
       "        MVIB       0.000074\n",
       "        MaxPOOLeE  0.000104\n",
       "R2      AVIB       0.001120\n",
       "        AvgPOOLoE  0.003546\n",
       "        MVIB       0.001231\n",
       "        MaxPOOLeE  0.001570\n",
       "RMSE    AVIB       0.000323\n",
       "        AvgPOOLoE  0.000449\n",
       "        MVIB       0.000177\n",
       "        MaxPOOLeE  0.000225"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_df = results_df.groupby(['Metrics', 'Model']).std()\n",
    "std_df['Score'] = std_df['Score'].apply(lambda x: x / 5)\n",
    "std_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
