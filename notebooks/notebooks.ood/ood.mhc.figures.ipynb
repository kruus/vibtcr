{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2213a439",
   "metadata": {},
   "source": [
    "# OOD figures\n",
    "Create figures of OOD experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e79b94",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0899699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import random\n",
    "import math\n",
    "from scipy import interp\n",
    "import statistics\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import collections\n",
    "from matplotlib import colors\n",
    "from numpy.random import normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c358de",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'FPR (95% TPR)',\n",
    "    'AUROC',\n",
    "    'AUPR',\n",
    "    'Detection error'\n",
    "]\n",
    "\n",
    "def fpr_at_x_tpr(true_values, predicted_values, cutoff=0.95):\n",
    "    \"\"\"Calculate FPR @X% TPR\"\"\"\n",
    "\n",
    "    tprs = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    auc = []\n",
    "    fpr, tpr, thresholds = roc_curve(true_values, predicted_values)\n",
    "\n",
    "    for fp, tp, threshold in zip(fpr, tpr, thresholds):\n",
    "        if tp >= cutoff:\n",
    "            return fp\n",
    "\n",
    "def detection_error_x_tpr(true_values, predicted_values, cutoff=0.95):\n",
    "    \"\"\"Calculate detection error Pe.\n",
    "    Measures the misclassification probability when TPR is 95%.\n",
    "    Pe = 0.5(1 - TPR) + 0.5FPR\n",
    "    \"\"\"\n",
    "\n",
    "    tprs = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    auc = []\n",
    "    fpr, tpr, thresholds = roc_curve(true_values, predicted_values)\n",
    "\n",
    "    for fp, tp, threshold in zip(fpr, tpr, thresholds):\n",
    "        if tp >= cutoff:\n",
    "            return 0.5 * (1 - tp) + 0.5 * fp\n",
    "\n",
    "def pr_auc(y_true, y_prob):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    return pr_auc\n",
    "\n",
    "def get_scores(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Compute a df with all classification metrics and respective scores.\n",
    "    \"\"\"\n",
    "\n",
    "    scores = [\n",
    "        fpr_at_x_tpr(y_true, y_prob),\n",
    "        roc_auc_score(y_true, y_prob),\n",
    "        pr_auc(y_true, y_prob),\n",
    "        detection_error_x_tpr(y_true, y_prob)\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(data={'score': scores, 'metrics': metrics})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87fdc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "login = os.getlogin( )\n",
    "\n",
    "DATA_BASE = f\"/home/{login}/Git/tcr/data/\"\n",
    "RESULTS_BASE = f\"/home/{login}/Git/tcr/notebooks/notebooks.ood/results/\"\n",
    "FIGURES_BASE = f\"/home/{login}/Git/tcr/notebooks/notebooks.ood/figures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b274dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_files = [\n",
    "    ('MSP', [pd.read_csv(RESULTS_BASE + f\"mhc.mvib.msp.aoe.rep-{i}.csv\") for i in range(5)]),\n",
    "    ('ODIN (Îµ=0.001, T=1000)', [pd.read_csv(RESULTS_BASE + f\"mhc.mvib.odin.aoe.T-1000.epsilon-0.001.rep-{i}.csv\") for i in range(5)]),\n",
    "    ('AVIB-R', [pd.read_csv(RESULTS_BASE + f\"mhc.mvib.kld-joint.aoe.rep-{i}.csv\") for i in range(5)]),\n",
    "    ('AVIB-Maha', [pd.read_csv(RESULTS_BASE + f\"mhc.mvib.aoe.maha.layer-0.epsilon-0.rep-{i}.csv\") for i in range(5)]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe057545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 24\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "sns.set_palette('magma', len(predictions_files))\n",
    "\n",
    "\n",
    "def make_roc_curve_plot(ax, true_values_list, predicted_values_list, cutoff, model_label):\n",
    "    \"\"\"Calculate ROC and AUC from lists of true and predicted values and draw.\"\"\"\n",
    "\n",
    "    tprs = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    auc = []\n",
    "    for true_values, predicted_values in zip(true_values_list, predicted_values_list):\n",
    "        fpr, tpr, thresholds = roc_curve(true_values, predicted_values)\n",
    "        auc.append(roc_auc_score(true_values, predicted_values))\n",
    "        tpr = interp(base_fpr, fpr, tpr)\n",
    "        tpr[0] = 0.0\n",
    "        tprs.append(tpr)\n",
    "    \n",
    "    tprs = np.array(tprs)\n",
    "    mean_tprs = tprs.mean(axis=0)\n",
    "\n",
    "    ax.plot(base_fpr, mean_tprs, label=model_label,linewidth=3)\n",
    "    \n",
    "    ax.set_title(\"ID: Human TCR set | OOD: Human MHC set\", y=1.04)\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.legend()\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    \n",
    "#     for fp, tp, threshold in zip(fpr, tpr, thresholds):\n",
    "#         if threshold < cutoff:\n",
    "#             ax.plot(fp, tp, marker='o', markersize=10, color='grey', alpha=0.75)\n",
    "#             break\n",
    "\n",
    "\n",
    "def make_uninformative_roc(ax):\n",
    "    ax.plot([0, 1], [0, 1], c='grey', linestyle='dashed', alpha=0.5,linewidth=3)\n",
    "    ax.legend()\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend(facecolor=\"white\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for predictions_file in predictions_files:\n",
    "    true_values_list, predicted_values_list = [], []\n",
    "    for i in range(5):\n",
    "        prediction_df = predictions_file[1][i]\n",
    "        true_values_list.append(prediction_df['sign'].to_numpy())\n",
    "        predicted_values_list.append(prediction_df[f'prediction_{i}'].to_numpy())\n",
    "\n",
    "    make_roc_curve_plot(\n",
    "        ax, \n",
    "        true_values_list, \n",
    "        predicted_values_list, \n",
    "        0.9,\n",
    "        predictions_file[0]\n",
    "    )\n",
    "make_uninformative_roc(ax)\n",
    "ax.tick_params(axis='x', pad=15)\n",
    "# ax.legend(loc='best')\n",
    "ax.legend(loc='best')\n",
    "legend = plt.legend(frameon = 1)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('white')\n",
    "ax.grid(axis='y')\n",
    "ax.grid(axis='x')\n",
    "plt.savefig(FIGURES_BASE + \"roc.mhc.svg\", format='svg', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(FIGURES_BASE + \"roc.mhc.png\", format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7476b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def make_prc_curve_plot(ax, true_values, predicted_values, model_label):\n",
    "    \"\"\"Calculate PRC and AUC from lists of true and predicted values and draw.\"\"\"\n",
    "    \n",
    "    reversed_mean_precision = 0.0\n",
    "    base_recall = np.linspace(1, 0, 100)\n",
    "    auc = []\n",
    "    \n",
    "    for true_values, predicted_values in zip(true_values_list, predicted_values_list):\n",
    "        precision, recall, thresholds = precision_recall_curve(true_values, predicted_values)\n",
    "        auc.append(pr_auc(true_values, predicted_values))\n",
    "        reversed_recall = np.fliplr([recall])[0]\n",
    "        reversed_precision = np.fliplr([precision])[0]\n",
    "        reversed_mean_precision += interp(base_recall, reversed_recall, reversed_precision)\n",
    "    \n",
    "    reversed_mean_precision /= 5\n",
    "    \n",
    "    ax.plot(base_recall, reversed_mean_precision, label=model_label, linewidth=3)\n",
    "    \n",
    "    ax.set_title(\"ID: Human TCR set | OOD: Human MHC set\", y=1.04)\n",
    "    ax.set_ylabel(\"Precision\")\n",
    "    ax.set_xlabel(\"Recall\")\n",
    "    ax.legend()\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.01])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for predictions_file in predictions_files:\n",
    "    true_values_list, predicted_values_list = [], []\n",
    "    for i in range(5):\n",
    "        prediction_df = predictions_file[1][i]\n",
    "        true_values_list.append(prediction_df['sign'].to_numpy())\n",
    "        predicted_values_list.append(prediction_df[f'prediction_{i}'].to_numpy())\n",
    "\n",
    "    make_prc_curve_plot(\n",
    "        ax, \n",
    "        true_values_list, \n",
    "        predicted_values_list, \n",
    "        predictions_file[0]\n",
    "    )\n",
    "\n",
    "ax.tick_params(axis='x', pad=15)\n",
    "# ax.legend(loc='best')\n",
    "ax.legend(loc='best')\n",
    "legend = plt.legend(frameon = 1)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('white')\n",
    "ax.grid(axis='y')\n",
    "ax.grid(axis='x')\n",
    "plt.savefig(FIGURES_BASE + \"prc.mhc.svg\", format='svg', dpi=300, bbox_inches='tight')\n",
    "plt.savefig(FIGURES_BASE + \"prc.mhc.png\", format='png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0f5946",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for predictions_file in predictions_files:\n",
    "    true_values_list, predicted_values_list = [], []\n",
    "    for i in range(5):\n",
    "        prediction_df = predictions_file[1][i]\n",
    "        y_true = prediction_df['sign'].to_numpy()\n",
    "        y_prob = prediction_df[f'prediction_{i}'].to_numpy()\n",
    "        \n",
    "        df = get_scores(y_true, y_prob)\n",
    "        df['method'] = predictions_file[0]\n",
    "        \n",
    "        df_list.append(df)\n",
    "results = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.groupby(['method', 'metrics']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae9b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_df = results.groupby(['method', 'metrics']).std()\n",
    "std_df['score'] = std_df['score'] / 5\n",
    "std_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb66df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
